lora:
  r: 8
  lora_alpha: 32
  lora_dropout: 0.1
adalora:
  init_r: 12
  target_r: 8
  beta1: 0.85
  beta2: 0.85
  tinit: 200
  tfinal: 1000
  deltaT: 10,
  lora_alpha: 32
  lora_dropout: 0.1
  inference_mode: False
prefixtuning:
  num_virtual_tokens: 20